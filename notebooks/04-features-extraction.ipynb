{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5848a21-a02c-4f25-a26c-c199ebbaa4fe",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e357bc9-0599-4d7b-ab62-bd90ca6002c8",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8c0371d-1e1d-47f4-9e25-3e9f31b4acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324d5ff-8e57-43d5-a9f9-fe01a3d265b3",
   "metadata": {},
   "source": [
    "## Import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82af37e4-f11a-4cef-849b-09c25aafab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "import utils\n",
    "from utils import extract_mfcc_features\n",
    "from utils import pad_features\n",
    "from utils import normalize_features\n",
    "from utils import augment_audio\n",
    "from utils import extract_prosodic_features\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import extract_mfcc_features\n",
    "from utils import pad_features\n",
    "from utils import normalize_features\n",
    "from utils import augment_audio\n",
    "from utils import extract_prosodic_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900baa40-1e8d-41db-a8af-8f75deb3e374",
   "metadata": {},
   "source": [
    "## Import metadata csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5317798e-0d54-4488-b35e-77bb6e692130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>emotion</th>\n",
       "      <th>dataset</th>\n",
       "      <th>actor</th>\n",
       "      <th>index</th>\n",
       "      <th>sample_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/processed/audio_16k/savee_OAF_angry_13...</td>\n",
       "      <td>angry</td>\n",
       "      <td>savee</td>\n",
       "      <td>OAF</td>\n",
       "      <td>132</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/processed/audio_16k/savee_YAF_fear_152...</td>\n",
       "      <td>fear</td>\n",
       "      <td>savee</td>\n",
       "      <td>YAF</td>\n",
       "      <td>1521</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/processed/audio_16k/savee_OAF_neutral_...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>savee</td>\n",
       "      <td>OAF</td>\n",
       "      <td>592</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/processed/audio_16k/savee_OAF_disgust_...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>savee</td>\n",
       "      <td>OAF</td>\n",
       "      <td>1177</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/processed/audio_16k/savee_OAF_disgust_...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>savee</td>\n",
       "      <td>OAF</td>\n",
       "      <td>709</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>../data/processed/audio_16k/crema-d_1065_happy...</td>\n",
       "      <td>happy</td>\n",
       "      <td>crema-d</td>\n",
       "      <td>1065</td>\n",
       "      <td>5247</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11314</th>\n",
       "      <td>../data/processed/audio_16k/crema-d_1031_neutr...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>crema-d</td>\n",
       "      <td>1031</td>\n",
       "      <td>2474</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11315</th>\n",
       "      <td>../data/processed/audio_16k/crema-d_1064_happy...</td>\n",
       "      <td>happy</td>\n",
       "      <td>crema-d</td>\n",
       "      <td>1064</td>\n",
       "      <td>5203</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11316</th>\n",
       "      <td>../data/processed/audio_16k/crema-d_1070_angry...</td>\n",
       "      <td>angry</td>\n",
       "      <td>crema-d</td>\n",
       "      <td>1070</td>\n",
       "      <td>5662</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11317</th>\n",
       "      <td>../data/processed/audio_16k/crema-d_1040_happy...</td>\n",
       "      <td>happy</td>\n",
       "      <td>crema-d</td>\n",
       "      <td>1040</td>\n",
       "      <td>3195</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11318 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_path  emotion  dataset  \\\n",
       "0      ../data/processed/audio_16k/savee_OAF_angry_13...    angry    savee   \n",
       "1      ../data/processed/audio_16k/savee_YAF_fear_152...     fear    savee   \n",
       "2      ../data/processed/audio_16k/savee_OAF_neutral_...  neutral    savee   \n",
       "3      ../data/processed/audio_16k/savee_OAF_disgust_...  disgust    savee   \n",
       "4      ../data/processed/audio_16k/savee_OAF_disgust_...  disgust    savee   \n",
       "...                                                  ...      ...      ...   \n",
       "11313  ../data/processed/audio_16k/crema-d_1065_happy...    happy  crema-d   \n",
       "11314  ../data/processed/audio_16k/crema-d_1031_neutr...  neutral  crema-d   \n",
       "11315  ../data/processed/audio_16k/crema-d_1064_happy...    happy  crema-d   \n",
       "11316  ../data/processed/audio_16k/crema-d_1070_angry...    angry  crema-d   \n",
       "11317  ../data/processed/audio_16k/crema-d_1040_happy...    happy  crema-d   \n",
       "\n",
       "      actor  index  sample_rate  \n",
       "0       OAF    132        16000  \n",
       "1       YAF   1521        16000  \n",
       "2       OAF    592        16000  \n",
       "3       OAF   1177        16000  \n",
       "4       OAF    709        16000  \n",
       "...     ...    ...          ...  \n",
       "11313  1065   5247        16000  \n",
       "11314  1031   2474        16000  \n",
       "11315  1064   5203        16000  \n",
       "11316  1070   5662        16000  \n",
       "11317  1040   3195        16000  \n",
       "\n",
       "[11318 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/metadata.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5943a-1c1d-4363-9e35-de1bdd384695",
   "metadata": {},
   "source": [
    "## (MFCCs + Deltas -> Normalize -> Pad) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c668a-729d-4128-9b8c-d57c0103e5b4",
   "metadata": {},
   "source": [
    "### Make sure dir exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ca57b6-a5a4-4f1e-ace6-0620df941657",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_plus_deltas_features_metadata_dir = \"../data/features/audio_16k/mfcc+deltas\"\n",
    "mfcc_plus_deltas_features_dir = \"../data/features/audio_16k/mfcc+deltas/audio_features\"\n",
    "os.makedirs(mfcc_plus_deltas_features_metadata_dir, exist_ok=True)\n",
    "os.makedirs(mfcc_plus_deltas_features_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c19595-288a-4f76-b2a9-1628c3d4e869",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6245d15-145a-46ef-8558-33c5b934e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|███████████████████████████████████████████████████████| 11318/11318 [01:41<00:00, 111.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Extraction Completed!\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"Extracting features\"):\n",
    "    try:\n",
    "        file_path = row.file_path\n",
    "        sample_rate = row.sample_rate\n",
    "        \n",
    "        audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "        # Extract MFCCs + deltas\n",
    "        features = extract_mfcc_features(\n",
    "            audio, \n",
    "            sr,\n",
    "            n_mfcc=40,\n",
    "            hop_length=512,\n",
    "            n_fft=1024\n",
    "        ) # Shape: (120, time_steps)\n",
    "\n",
    "        # Stack all features together\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        # Normalize\n",
    "        features = normalize_features(features)\n",
    "        # Shape: (120, 150) - normalized\n",
    "\n",
    "        # Pad to fixed length\n",
    "        features = pad_features(features, max_len=150)\n",
    "        # Shape: (120, 150)\n",
    "\n",
    "        # # Add channel dimension for CNN\n",
    "        # features = features[np.newaxis, ...]\n",
    "        # # Shape: (1, 120, 150)\n",
    "\n",
    "        # Save as .npy\n",
    "        base_name = os.path.basename(file_path).replace(\".wav\", \".npy\")\n",
    "        out_path = os.path.join(mfcc_plus_deltas_features_dir, base_name)\n",
    "        np.save(out_path, features)\n",
    "\n",
    "        metadata.append([out_path, row.emotion, row.dataset, row.actor, row.index, row.sample_rate])\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(f\"Error processing {file_path}: {e}\") \n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame(metadata, columns=[\"file_path\",\"emotion\",\"dataset\",\"actor\", \"index\",\"sample_rate\"])\n",
    "csv_path = os.path.join(mfcc_plus_deltas_features_metadata_dir, 'metadata.csv')\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "df.head()\n",
    "\n",
    "print(\"Features Extraction Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2582ae-c4eb-4804-a929-3538cd455f5e",
   "metadata": {},
   "source": [
    "## (MFCCs + Deltas -> Prosidic -> Normalize -> Pad) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fce00-6571-4d64-bae9-b00925f72502",
   "metadata": {},
   "source": [
    "### Make sure dir exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0b0fbe1-3a14-47cb-8144-bc5c6bbb93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_plus_deltas_prosodic_features_metadata_dir = \"../data/features/audio_16k/mfcc+deltas_prosodic\"\n",
    "mfcc_plus_deltas_prosodic_features_dir = \"../data/features/audio_16k/mfcc+deltas_prosodic/audio_features\"\n",
    "os.makedirs(mfcc_plus_deltas_prosodic_features_metadata_dir, exist_ok=True)\n",
    "os.makedirs(mfcc_plus_deltas_prosodic_features_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b452d61-20fc-4927-b863-43483d8fa408",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13087176-13d1-4fc9-8643-ceddb0566d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████████████████████████████████████| 11318/11318 [1:19:30<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Extraction Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"Extracting features\"):\n",
    "    try:\n",
    "        file_path = row.file_path\n",
    "        sample_rate = row.sample_rate\n",
    "\n",
    "        audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "        mfccs = extract_mfcc_features(\n",
    "            audio, \n",
    "            sr,\n",
    "            n_mfcc=40,\n",
    "            hop_length=512,\n",
    "            n_fft=1024\n",
    "        ) # Shape: (120, time_steps)\n",
    "\n",
    "        prosodic = extract_prosodic_features(audio, sr)\n",
    "\n",
    "        # Stack all features together\n",
    "        features = np.vstack([mfccs, prosodic])\n",
    "\n",
    "        # Normalize\n",
    "        features = normalize_features(features)\n",
    "        # Shape: (120, 150) - normalized\n",
    "\n",
    "        # Pad to fixed length\n",
    "        features = pad_features(features, max_len=150)\n",
    "        # Shape: (120, 150)\n",
    "\n",
    "        # # Add channel dimension for CNN\n",
    "        # features = features[np.newaxis, ...]\n",
    "        # # Shape: (1, 120, 150)\n",
    "\n",
    "        # Save as .npy\n",
    "        base_name = os.path.basename(file_path).replace(\".wav\", \".npy\")\n",
    "        out_path = os.path.join(mfcc_plus_deltas_prosodic_features_dir, base_name)\n",
    "        np.save(out_path, features)\n",
    "\n",
    "        metadata.append([out_path, file_path, row.emotion, row.dataset, row.actor, row.index, row.sample_rate])    \n",
    "\n",
    "    except Exception as e: \n",
    "        print(f\"Error processing {file_path}: {e}\") \n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame(metadata, columns=[\"file_path\", \"audio_file_path\", \"emotion\", \"dataset\", \"actor\", \"index\", \"sample_rate\"])\n",
    "csv_path = os.path.join(mfcc_plus_deltas_prosodic_features_metadata_dir, 'metadata.csv')\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "df.head()\n",
    "\n",
    "print(\"Features Extraction Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060ce70-0c5b-4cf6-ae27-f3e3b9231dca",
   "metadata": {},
   "source": [
    "## (Data Augmentation -> MFCCs + Deltas -> Prosidic -> Normalize -> Pad) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9d7b0-93ca-48a9-91a5-88bd3d3cfb4b",
   "metadata": {},
   "source": [
    "### Make sure dir exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e44b610-cdf7-467a-8cc9-3b1c78ee5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_mfcc_plus_deltas_prosodic_features_metadata_dir = \"../data/features/audio_16k/augmented_mfcc+deltas_prosodic\"\n",
    "augmented_mfcc_plus_deltas_prosodic_features_dir = \"../data/features/audio_16k/augmented_mfcc+deltas_prosodic/audio_features\"\n",
    "os.makedirs(augmented_mfcc_plus_deltas_prosodic_features_metadata_dir, exist_ok=True)\n",
    "os.makedirs(augmented_mfcc_plus_deltas_prosodic_features_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd71081-6561-4ef3-ae17-57d57734e318",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a1cfdd-35c8-414b-bae1-5bae4f7f7466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████████████████████████████████████| 11318/11318 [5:24:33<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Extraction Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"Extracting features\"):\n",
    "    try:\n",
    "        file_path = row.file_path\n",
    "        sample_rate = row.sample_rate\n",
    "\n",
    "        augmented_audios = augment_audio(file_path, sample_rate)\n",
    "\n",
    "        for aug_idx, (aug_audio, aug_name) in enumerate(augmented_audios):\n",
    "            mfccs = extract_mfcc_features(\n",
    "                aug_audio, \n",
    "                sample_rate,\n",
    "                n_mfcc=40,\n",
    "                hop_length=512,\n",
    "                n_fft=1024\n",
    "            ) # Shape: (120, time_steps)\n",
    "    \n",
    "            prosodic = extract_prosodic_features(aug_audio, sample_rate)\n",
    "    \n",
    "            # Stack all features together\n",
    "            features = np.vstack([mfccs, prosodic])\n",
    "    \n",
    "            # Normalize\n",
    "            features = normalize_features(features)\n",
    "            # Shape: (120, 150) - normalized\n",
    "    \n",
    "            # Pad to fixed length\n",
    "            features = pad_features(features, max_len=150)\n",
    "            # Shape: (120, 150)\n",
    "    \n",
    "            # # Add channel dimension for CNN\n",
    "            # features = features[np.newaxis, ...]\n",
    "            # # Shape: (1, 120, 150)\n",
    "    \n",
    "            # Save as .npy\n",
    "            original_name = os.path.basename(file_path).replace(\".wav\", \"\")\n",
    "            base_name = f\"{original_name}_{aug_name}.npy\"\n",
    "            out_path = os.path.join(augmented_mfcc_plus_deltas_prosodic_features_dir, base_name)\n",
    "            np.save(out_path, features)\n",
    "    \n",
    "            metadata.append([out_path, file_path, row.emotion, aug_name, row.dataset, row.actor, row.index, row.sample_rate])    \n",
    "\n",
    "    except Exception as e: \n",
    "        print(f\"Error processing {file_path}: {e}\") \n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame(metadata, columns=[\"file_path\", \"audio_file_path\", \"emotion\", \"augmentation\", \"dataset\", \"actor\", \"index\", \"sample_rate\"])\n",
    "csv_path = os.path.join(augmented_mfcc_plus_deltas_prosodic_features_metadata_dir, 'metadata.csv')\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "df.head()\n",
    "\n",
    "print(\"Features Extraction Completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
